




<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Federated Open OnDemand ::  GOOD 2025 :: pretalx</title>
        <meta name="title" content="Federated Open OnDemand  - GOOD 2025 pretalx">
        <meta name="description" content="Open OnDemand (OOD) is typically deployed in, or close to the supercomputer, usually on login or utility nodes, where the supercomputer file system can be mounted, direct access to the scheduler exists, and compute nodes can be accessed. However, in cases where the supercomputers are geographically distributed or managed by external organizations, these pre-requisites may not be fulfilled.

This talk explores the possibilities and challenges of deploying OOD in a different environment than the supercomputer itself, enabling the possibility of providing access to multiple remote supercomputers through a single centralized instance of OOD.

As part of the exploration work, CSC developed two prototypes of a centralized OOD instance to discover challenges and test potential solutions. Based on the prototypes, the main technical challenges consist of identity and access management, file system access, compute node access, scheduler access and potential performance concerns.

The first prototype was based on direct SSH access to the national supercomputers, with quick-and-dirty SSHFS mounts to explore the other challenges of federated OOD. The second prototype utilized FirecREST for accessing the supercomputer, and included an additional abstraction layer to solve the challenges related to the file system. Future work in this area consists of building a production-ready implementation of a federated OOD instance.

The goal of the talk is to provide a foundation for future discussion surrounding the topic, gather ideas for technical solutions and future development, as well as provide insight about the topic to other organizations interested in achieving a single, centralized OOD instance that could provide access to multiple supercomputers.">
        <meta name="application-name" content="pretalx">
        <meta name="generator" content="pretalx">
        <meta name="keywords" content="GOOD 2025, 2025, 2025, schedule, talks, cfp, call for papers, conference, submissions, organizer">
        
        <meta name="robots" content="index, follow">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#C91235">
        <meta name="HandheldFriendly" content="True"/>
        <meta property="thumbnail" content="https://cfp.openondemand.org/2025/talk/7CWQLP/og-image">
    <meta property="og:image" content="https://cfp.openondemand.org/2025/talk/7CWQLP/og-image">
        <meta property="og:title" content="Federated Open OnDemand GOOD 2025">
        <meta property="og:description" content="Open OnDemand (OOD) is typically deployed in, or close to the supercomputer, usually on login or utility nodes, where the supercomputer file system can be mounted, direct access to the scheduler exists, and compute nodes can be accessed. However, in cases where the supercomputers are geographically distributed or managed by external organizations, these pre-requisites may not be fulfilled.

This talk explores the possibilities and challenges of deploying OOD in a different environment than the supercomputer itself, enabling the possibility of providing access to multiple remote supercomputers through a single centralized instance of OOD.

As part of the exploration work, CSC developed two prototypes of a centralized OOD instance to discover challenges and test potential solutions. Based on the prototypes, the main technical challenges consist of identity and access management, file system access, compute node access, scheduler access and potential performance concerns.

The first prototype was based on direct SSH access to the national supercomputers, with quick-and-dirty SSHFS mounts to explore the other challenges of federated OOD. The second prototype utilized FirecREST for accessing the supercomputer, and included an additional abstraction layer to solve the challenges related to the file system. Future work in this area consists of building a production-ready implementation of a federated OOD instance.

The goal of the talk is to provide a foundation for future discussion surrounding the topic, gather ideas for technical solutions and future development, as well as provide insight about the topic to other organizations interested in achieving a single, centralized OOD instance that could provide access to multiple supercomputers.">
        <meta property="og:url" content="http://testserver/2025/talk/7CWQLP/">
        <meta property="twitter:card" content="summary">

        
            <link rel="icon" type="image/png" sizes="32x32" href="/good2025/schedule/static/common/img/favicon-32x32.38c2aab28d3a.png">
            <link rel="icon" type="image/png" sizes="16x16" href="/good2025/schedule/static/common/img/favicon-16x16.02f8a56e1af3.png">
        

        <link rel="stylesheet" type="text/css" href="/good2025/schedule/static/common/scss/uncompressed.cabbf3759e3e.css" />
        
            <link rel="stylesheet" type="text/css" href="/good2025/schedule/static/vendored/fullcalendar/fullcalendar.min.ba055a2cd2b3.css"/>
            <link rel="stylesheet" type="text/css" href="/good2025/schedule/media/2025/cfp.b4fdc45e320a46e0.css"/>
            <link rel="stylesheet" type="text/css" href="/good2025/schedule/media/2025/agenda.4ecfa7153a486dbb.css"/>
        
        
        <script src="/good2025/schedule/static/CACHE/js/output.079684506270.js" defer></script>
        
    
    <link rel="alternate" type="application/json" title="GOOD 2025 API" href="https://cfp.openondemand.org/api/events/2025/talks/7CWQLP" />

    
    

    </head>
    <body data-datetimeformat="YYYY-MM-DD HH:mm:ss" data-dateformat="YYYY-MM-DD" data-datetimelocale="en">
        <div id="top-bg" class="header pcb">
            
        </div>
        
        <div class="container" id="main-container">
            <header>
                <h1>
                    <a href="
    /2025/schedule/
">
                        
                            GOOD 2025
                        
                    </a>
                </h1>

                <div class="d-flex" id="header-row">
                    
                    
                </div>
            </header>
            <div class="card" id="main-card">
                <main>
                    

                    
    
    
    <article>
        
        <h3 class="talk-title">
            <div class="heading-with-buttons">
                Federated Open OnDemand
                <div class="buttons" id="talk-buttons">
                    
                        <a class="btn btn-outline-primary" href="/good2025/schedule/talk/7CWQLP.ics">
                            <i class="fa fa-calendar"></i> .ical
                        </a>
                    
                    
                    
                </div>
            </div>
            <small>
                
                    03-18, 16:00â€“16:25 (US/Eastern), Tsai Auditorium (CGIS S010) <i class="fa fa-question-circle" data-toggle="tooltip" title="S010"></i>
                
                
                
            </small>
        </h3>
        <div class="talk row">
            <div class="talk-content">
                
                
                
                <section class="abstract">
                    <p>Some organizations, such as CSC - IT Center for Science, provide the users with access to multiple supercomputers, where each of the supercomputers may have completely separate instances of Open OnDemand. This leads to a fragmented user experience, where the user is required to log in to another instance to access another supercomputer, as well as increased time spent on maintaining multiple instances. This talk targets system administrators, service owners, and other persons responsible for maintaining and developing Open OnDemand instances, and discusses the benefits and challenges of providing a single instance of Open OnDemand, which is connected to all of the organization's supercomputers and potentially even partner organizations' supercomputers.</p>
                </section>
                
                    <hr />
                
                <section class="description">
                    <p>Open OnDemand (OOD) is typically deployed in, or close to the supercomputer, usually on login or utility nodes, where the supercomputer file system can be mounted, direct access to the scheduler exists, and compute nodes can be accessed. However, in cases where the supercomputers are geographically distributed or managed by external organizations, these pre-requisites may not be fulfilled.</p>
<p>This talk explores the possibilities and challenges of deploying OOD in a different environment than the supercomputer itself, enabling the possibility of providing access to multiple remote supercomputers through a single centralized instance of OOD.</p>
<p>As part of the exploration work, CSC developed two prototypes of a centralized OOD instance to discover challenges and test potential solutions. Based on the prototypes, the main technical challenges consist of identity and access management, file system access, compute node access, scheduler access and potential performance concerns.</p>
<p>The first prototype was based on direct SSH access to the national supercomputers, with quick-and-dirty SSHFS mounts to explore the other challenges of federated OOD. The second prototype utilized FirecREST for accessing the supercomputer, and included an additional abstraction layer to solve the challenges related to the file system. Future work in this area consists of building a production-ready implementation of a federated OOD instance.</p>
<p>The goal of the talk is to provide a foundation for future discussion surrounding the topic, gather ideas for technical solutions and future development, as well as provide insight about the topic to other organizations interested in achieving a single, centralized OOD instance that could provide access to multiple supercomputers.</p>
                </section>
                
            </section>
            
            <section>
                
            </section>
        </div>
    </div>
    
        
            <div class="pretalx-session">
                <div class="pretalx-session-time-box avatar">
                    <a href="/good2025/schedule/speaker/TKYXWR/">
                        <div class="avatar-wrapper">
                            
                                <img src="/good2025/schedule/speaker/avatar.svg">
                            
                        </div>
                    </a>
                </div>
                <div class="pretalx-session-info">
                    <div class="title">
                        <a href="/good2025/schedule/speaker/TKYXWR/">Robin Karlsson [CSC - IT Center for Science]</a>
                    </div>
                    <div class="abstract"><p>Working at CSC - IT Center for Science in Finland with configuring and developing our instances of Open OnDemand for both our national supercomputers Puhti and Mahti, and the European supercomputer LUMI, hosted by CSC.</p></div>
                    
                </div>
            </div>
        
    
    </article>


                </main>
            </div>
            <footer>
                
                    <div id="exporttimestamp" class="text-muted">
                        
                        This is a static export generated at 2025-07-09 17:45 EDT
                    </div>
                
                


    powered by <a href="https://pretalx.com" target="_blank" rel="noopener">pretalx</a>


                
                    &middot;
                    <a href="mailto:jim@numfocus.org">Contact us</a>
                
                
                
            </footer>
        </div>
    </body>
</html>
